---
  title: "Project Part II"
output: html_document
date: "2025-05-15"
---

```{r}
libs <- c("tidyverse", "tidymodels", "vip", "rpart.plot", "kknn", "ggplot2")

installed_libs <- libs %in% rownames(installed.packages())

if (any(installed_libs == FALSE)) {
  install.packages(libs[!installed_libs])
}

# Load libraries
library(tidyverse)
library(tidymodels)
library(vip)          # For variable importance plots
library(rpart.plot)
library(kknn)
library(ggplot2)
```

```{r}
gift_gender_processed <- read_csv('gifts_gender_processed.csv')
gifts_age_processed <- read_csv('gifts_age_processed.csv')
historical_spending_processed <- read_csv('historical_spending_processed.csv')
```

### Decision Tree

```{r}
ga_recipe_tree <- recipe(
  EveningOut ~ ., 
  data = gifts_age_processed 
) %>%
  step_rm(Age, HighestSpending) %>% 
  step_YeoJohnson(all_numeric_predictors(), -all_outcomes()) %>% 
  step_normalize(all_numeric_predictors(), -all_outcomes()) 
prep(ga_recipe_tree) %>%
  bake(new_data = head(gifts_age_processed))
```

```{r}

tree_spec_reg <- decision_tree(
  cost_complexity = 0.01, 
  tree_depth = 3,         
  min_n = 2               
) %>%
  set_engine("rpart") %>%
  set_mode("regression")

print(tree_spec_reg)

tree_workflow_reg <- workflow() %>%
  add_model(tree_spec_reg) %>%
  add_recipe(ga_recipe_tree)

print(tree_workflow_reg)

fitted_tree_reg <- fit(tree_workflow_reg, data = gifts_age_processed)

print(fitted_tree_reg)

final_tree_rpart_fit_simple <- extract_fit_engine(fitted_tree_reg)

```

```{r}
rpart.plot(
  final_tree_rpart_fit_simple,
  roundint = FALSE,
  box.palette = "BuGn",
  extra = 1,
  tweak = 1.2,
  main = "Decision Tree Regression"
)
```

```{r}
vip(fitted_tree_reg) +
  labs(title = "Decision Tree Regression Variable Importance")

tree_predictions <- predict(fitted_tree_reg, new_data = gifts_age_processed) %>%
  bind_cols(gifts_age_processed %>% select(EveningOut)) 

metrics_simple <- tree_predictions %>%
  metrics(EveningOut, .pred)

print("Metrics on the full 6-record dataset:")
print(metrics_simple)
```

```{r}
ggplot(tree_predictions, aes(x = EveningOut, y = .pred)) +
  geom_point(size = 3) +
  geom_abline(intercept = 0, slope = 1, linetype = 'dashed', color = 'red') +
  labs(title = 'Decision Tree Regression: Predicted vs. Actual EveningOut Spending (Full Dataset)',
       subtitle = 'Model fitted on all 6 records - results prone to overfitting',
       x = 'Actual EveningOut Spending',
       y = 'Predicted EveningOut Spending') +
  theme_minimal()
```

### Linear Regression

```{r}
historical_spending_lm <- historical_spending_processed %>% 
  select(-AnnualSpending_tot, -HighestSpending)

lr_model <- lm(Jewelry ~ Year, data = historical_spending_lm)

# Create future years for prediction (5 years ahead)
future_years <- tibble(Year = 2024:2028)

# Predict jewelry spending for future years
future_years <- future_years %>%
  mutate(Predicted_Jewelry = predict(lr_model, newdata = future_years))

# Combine historical and predicted data for plotting
plot_data <- historical_spending_lm %>%
  select(Year, Jewelry) %>%
  mutate(Type = "Actual") %>%
  bind_rows(
    future_years %>%
      rename(Jewelry = Predicted_Jewelry) %>%
      mutate(Type = "Predicted")
  )

# Plot the data
ggplot(plot_data, aes(x = Year, y = Jewelry, color = Type)) +
  geom_point(size = 3) +
  geom_line() +
  labs(title = "Jewelry Spending Forecast",
       y = "Jewelry Spending (USD)",
       x = "Year") +
  theme_minimal()
```

```{r}
summary(lr_model)
```

### KNN Regression

```{r}
historical_spending_knn <- historical_spending_processed %>%
  select(-Year, -AnnualSpending_tot, -HighestSpending, -SpendingChange)
historical_spending_knn
```

```{r}
set.seed(314)

hist_split <- initial_split(historical_spending_knn, prop = 0.9)

hist_training <- training(hist_split)
hist_test <- testing(hist_split)
cat('Historical spending training set dimensions:', dim(hist_training), '\n')
cat('Historical spending testing set dimensions:', dim(hist_test), '\n')
```

```{r}
hist_recipe <- recipe(
  Jewelry ~ ., 
  data = hist_training 
) %>%
  step_YeoJohnson(all_numeric_predictors(), -all_outcomes()) %>% 
  step_normalize(all_numeric_predictors(), -all_outcomes()) 
```

```{r}
hist_recipe_prepped <- prep(hist_recipe, training = hist_training)
baked_hist_training <- bake(hist_recipe_prepped, new_data = hist_training)
cat('First few rows of baked historical spending training data:\n')
glimpse(baked_hist_training)
```

```{r}
knn_model_spec_reg <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine('kknn') %>% 
  set_mode('regression')

knn_model_spec_reg
```

```{r}
knn_wf_reg <- workflow() %>%
  add_model(knn_model_spec_reg) %>%
  add_recipe(hist_recipe)

knn_wf_reg
```

```{r}
k_grid_reg <- tibble(neighbors = c(1, 2))
k_grid_reg
```

```{r}
set.seed(314)
hist_folds <- vfold_cv(hist_training, v = 2)
knn_tuning_reg <- tune_grid(
  knn_wf_reg,
  resamples = hist_folds,
  grid = k_grid_reg,
  metrics = metric_set(rmse, rsq, mae)
)

knn_tuning_reg
```

```{r}
autoplot(knn_tuning_reg) +
  labs(title = 'KNN Hyperparameter Tuning (Historical Spending Data)',
       subtitle = 'Performance vs. Number of Neighbors (k)') +
  theme_light()

```

```{r}
knn_tuning_reg %>%
  show_best(metric = 'rmse', n = 3)

best_k_reg <- knn_tuning_reg %>%
  select_best(metric = 'rmse')

print('Best k for regression:')
print(best_k_reg)
```

```{r}
final_knn_wf_reg <- knn_wf_reg %>%
  finalize_workflow(best_k_reg)

final_knn_wf_reg
```

Â 

```{r}
last_fit_knn_reg <- final_knn_wf_reg %>%
  last_fit(split = hist_split)
```

```{r}
last_fit_knn_reg %>%
  collect_metrics()
```

```{r}
knn_test_predictions_reg <- last_fit_knn_reg %>%
  collect_predictions()
```

```{r}
ggplot(knn_test_predictions_reg, aes(x = Jewelry, y = .pred)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = 'dashed', color = 'red') +
  labs(title = 'KNN Regression: Predicted vs. Actual Jewelry Spending (Test Data)',
       x = 'Actual Jewerly Spending',
       y = 'Predicted Jewerly Spending') +
  theme_minimal()
```

```{r}
historical_spending_processed
```

## Summary

### 1. Decision Tree for Regression for gifts_age

-   'EveningOut' was set as a target variable, 'HighestSpending' feature was removed as it was derived based on comparison of other features including the target variable, so there's no sense to keep it. Prediction of 'EveningOut' variable would be helpful for entertainment places such as cinemas, restaurants, pubs, etc.

-   Interpretation of results: the Decision Tree graph indicates that the target variable primarily relies on the Age Group (set as ...1 on the graph)

-   Model's fit assessment: models fit was assessed with RMSE, Rsq and MAE metrics. Additionally, visualizations such as 'Predicted vs Actual' plot and Variable Importance plots were used.

-   Notes: gifts_age dataset is extremely small, that's why the decision tree was trained and tested on the whole dataset. Otherwise, the model would consist of a single split.

### 2. Linear Regression for historical spending

-   'Jewerly' spending was set a target variable, we used 'Year' as a single dependent feature to detect the time-based trend. Forecasting the jewerly spending would be helpful for the jewerly stores.

-   Interpretation of the results: p-value indicates that 'Year' is significant feature.

-   Model's fit assessment: models fit was assessed with multiple and adjusted R2, F-statistics, residual standard error as well as visual inspection of a plot. Our linear regression model explains approximately 56.6 % of the variance in Jewerly based on the Year.

### 3. KNN for historical spending
