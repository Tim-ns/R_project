---
title: "ProjectSummary"
output: html_document
date: "2025-06-30"
---

# Steps taken

## Part I EDA

### Data Loading and Initial Exploration (EDA):

-   Three datasets were loaded: `historical_spending.csv`, `gifts_age.csv`, and `gifts_gender.csv`.

-   Initial data understanding was performed using `glimpse()` and `skim()` to inspect structure, data types, and summary statistics, including checks for missing values. None of datasets contains missing values

### Data Extension / Feature Engineering: New, insightful features were computed for each dataset to enrich the analysis:

-   `historical_spending` dataset:

    -   `AnnualSpending_tot`: Calculated as the total spending across all gift categories for each year, providing an overall spending trend.

    -   `SpendingChange`: Computed the year-over-year percentage change in `PerPerson` spending to observe spending growth or decline.

    -   `HighestSpending`: Identified the gift category with the highest spending each year, highlighting dominant categories.

-   `gifts_age` dataset:

    -   `Age_cat`: Converted categorical age ranges into numerical categories (1-6) for easier processing in models.

    -   `HighestSpending`: Determined the gift category with the highest spending for each age group.

    -   `Affinity_` indices: Calculated an "Affinity Index" for each gift category per age group. An index \> 100 indicates that an age group is more likely to purchase a product compared to the overall average, providing insights into group-specific preferences.

-   `gifts_gender` dataset:

    -   `HighestSpending`: Identified the gift category with the highest spending for each gender.

    -   `Affinity_` indices: Computed "Affinity Index" for each gift category per gender, similar to the age groups, to understand gender-specific purchasing likelihoods.

### Data Visualization (EDA Plots)

A variety of plots were generated to visualize trends, distributions, and relationships within the data:

-   Affinity Index vs Age Group: Showed popular gift categories for different age ranges (e.g., Clothing and Jewelry for 18-44, Greeting Cards for 45+), and an overall trend of decreasing gift-buying percentage with age.

-   Affinity Index vs Gender: Illustrated gender-based spending likelihoods, noting women's higher likelihood to buy gifts except Flowers and Jewelry.

-   Change of Total Spending over Time: Compared nominal and real (inflation-adjusted) total spending, indicating an overall increase in purchasing power over time.

-   Average Spending per Gift Category over Time (Stacked Area Plot): Visualized the proportion of spending on each category annually, showing Jewelry and Evening Out as largest portions and a limited growth from 2015-2019.

-   Distribution of Spending Across Each Gift Category: Box plots displayed the range, median, and variability of spending for each category.

-   Gift Category Spending Distribution by Age: Box plots to compare buying prevalences across categories within age groups.

-   Percentage of Celebrating by Age Group: showed that the 18-24 age group had the highest percentage of people celebrating Valentine's Day, with a decreasing trend as age increases.

-   Average Spending on Flowers by Age Group: showed that the 18-24 age group had the highest percentage of people celebrating Valentine's Day, with a decreasing trend as age increases.

-   Valentine's Day Spending by Age Group and Gift Type: This stacked bar chart shows the distribution of gift spending types by age group. Each bar represents an age group and is divided by different gift types, illustrating which categories dominate within each age segment. In younger age groups like 18-24, Candy and Evening Out appear to constitute larger portions, while in older groups, other categories might become more prominent such as Greeting cards.

-   Average Gift Spending by Age Groups: This bar chart summarizes the average total spending per person in each age group across all gift categories.There's a general trend of decreasing average gift spending as age increases, which aligns with the "Percentage of Celebrating by Age Group" plot.

## Part II Modelling

During that phase, three regression models were developed to predict spending, each with a different objective and approach. Including:

-   **Decision Tree for Regression:**

    Objective: Predict `EveningOut` spending using the gifts_age_processed dataset.

    Preprocessing: `Age` and `HighestSpending` were removed, and remaining numeric predictors underwent Yeo-Johnson transformation and normalization.

    Model Specification: A decision_tree model with cost_complexity = 0.01, tree_depth = 3, and min_n = 2 was defined using the rpart engine.

    Evaluation: The model was fitted and evaluated on the entire 6-record gifts_age_processed dataset, using RMSE, R-squared, and MAE. Variable importance and the tree structure were visualized. The model faces limitations due to the dataset's size.

-   **Linear Regression:**

    Objective: Forecast Jewelry spending based on Year using historical_spending_lm to detect time-based trends.

    Model: A simple linear model lm(Jewelry \~ Year) was fitted.

    Evaluation: The summary() of the model provided statistical insights, including R-squared (0.5655), residual standard error (4.26), and p-values (showing Year as a significant predictor). A forecast plot visualized historical trends and future predictions.

-   **KNN Regression:**

Objective: Predict Jewelry spending using other spending categories and Age_cat from historical_spending_knn, offering an alternative approach to the linear model.

Preprocessing: Numeric predictors were transformed using Yeo-Johnson and normalized.

Data Split: The dataset was split into 90% training and 10% testing sets using initial_split().

Hyperparameter Tuning: A k grid of 1 and 2 neighbors was tuned using 2-fold cross-validation (vfold_cv) on the training data, optimizing for RMSE.

Evaluation: The final workflow was fitted to the training data and evaluated on the test set using last_fit(), collecting RMSE, R-squared, and MAE. A plot of predicted vs. actual values on the test data was generated.

# Conclusions and Reflections

## What went well-defined and what was difficult?

### Well

The project successfully demonstrated various data manipulation and visualization techniques, effectively telling a story through plots. The application of different models (tree, linear, KNN) was also well-executed. Feature engineering, such as creating `HighestSpending` and `Affinity_` indices, provided valuable new insights.

### Challenges

A significant challenge was the extremely small size of the provided datasets (13, 6 and 2 records), which severely limited the robustness of the Decision Tree model's evaluation and made proper train/test splitting for generalizable performance assessment difficult. Directly comparing the Linear Regression's "residual standard error" (a training-based metric) with KNN's test set metrics was statistically inappropriate without re-evaluating the linear model on a test set.

## What could have been done better?

Consistent Evaluation: All models, especially if intended for performance comparison, should have been evaluated on a consistent, independent test set. This would involve creating a single train/test split at the beginning for all models predicting `Jewelry` or `EveningOut` that share data. However, this would require larger datasets. What was the most challenging, and what was the most interesting?

## What was the most challenging, interesting?

### Most Challenging

-   Dealing with the extremely small datasets and the implications for model reliability and evaluation was likely the most challenging aspect.
-   The issue with the KNN's R-squared also presented a significant challenge.

### Most Interesting:

-   The feature engineering, particularly the creation of `Affinity_` Indices and `HighestSpending`, was very interesting as it provided a clear, interpretable measure of spending likelihood by age and gender.
-   The diverse set of visualizations, from stacked area plots to box plots and time series forecasts, effectively communicated hidden data patterns.

## What was the most useful?

-   The `Affinity_` Index feature was very useful for understanding consumer preferences by demographic.

-   The tidymodels framework provided a consistent and robust way to build and evaluate the Decision Tree and KNN models, promoting good machine learning practices (like preprocessing pipelines and hyperparameter tuning).

-   The Linear Regression model was particularly useful for its high interpretability and clear statistical significance in demonstrating a trend in `Jewelry` spending over time.

-   The various visualizations were invaluable for initial data exploration and communicating insights.

## What would you do differently if you were starting the project from scratch?

-   Extend the datasets: The obtained datasets are too small to build meaningful models. We could try extending the datasets by generating more data (i.e. with AI) or searching for larger datasets.

-   Unified Data Splitting: Implement a single, unified train/test split for all models that predict the same target variable (e.g., Jewelry) to ensure fair comparison of their generalization performance.

## What would you do differently if you had more time?

-   Collect More Data or Extend the Datasets: If feasible, acquire or simulate more data, to enable more robust modeling.

-   Broader Hyperparameter Tuning: Conduct more extensive hyperparameter tuning for the KNN model (and potentially the Decision Tree) with a wider range of k values and more cross-validation folds after obtaining larger datasets.

-   Advanced Models: Explore more complex or ensemble modeling techniques (e.g., Random Forests, Gradient Boosting Machines) that might capture more intricate relationships.

## What would you do differently if you had more knowledge/resources?

-   Collect More Data or Extend the Datasets: Acquire or simulate more data, to enable more robust modeling. Alternatively, we could select different datasets.
